{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/singithi03/Data-Analytics_s5214680/blob/Lab-7/News_Topic_Modelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwp7KySEasty"
      },
      "source": [
        "# Topic Modelling for News"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJ2JWkAGast0"
      },
      "source": [
        "![](https://images.unsplash.com/photo-1495020689067-958852a7765e?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1050&q=80)\n",
        "\n",
        "Photo by [Roman Kraft](https://unsplash.com/photos/_Zua2hyvTBk)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9lnsTv2ast0"
      },
      "source": [
        "This exercise is about modelling the main topics of a database of News headlines."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTUCTHhUast0"
      },
      "source": [
        "Begin by importing the needed libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kEY5sK0Past0"
      },
      "outputs": [],
      "source": [
        "# TODO: import needed libraries\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9RLHOqFast1"
      },
      "source": [
        "Load the data in the file `random_headlines.csv`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "LIx4ezNNast1",
        "outputId": "25bfdc63-a307-41cd-9c71-a3b4d818f3f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   publish_date                          headline_text\n",
              "0      20120305  ute driver hurt in intersection crash\n",
              "1      20081128           6yo dies in cycling accident\n",
              "2      20090325          bumper olive harvest expected\n",
              "3      20100201     replica replaces northernmost sign\n",
              "4      20080225           woods targets perfect season"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-85b33a46-299a-4b66-a755-c581371775f5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>publish_date</th>\n",
              "      <th>headline_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20120305</td>\n",
              "      <td>ute driver hurt in intersection crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20081128</td>\n",
              "      <td>6yo dies in cycling accident</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20090325</td>\n",
              "      <td>bumper olive harvest expected</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20100201</td>\n",
              "      <td>replica replaces northernmost sign</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20080225</td>\n",
              "      <td>woods targets perfect season</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-85b33a46-299a-4b66-a755-c581371775f5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-85b33a46-299a-4b66-a755-c581371775f5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-85b33a46-299a-4b66-a755-c581371775f5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# TODO: load the dataset\n",
        "df = pd.read_csv('random_headlines.csv')\n",
        "print(df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdnIGk8Nast2"
      },
      "source": [
        "This is always a good idea to perform some EDA (exploratory data analytics) on a dataset..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsxXLX3East2",
        "outputId": "13c8beaa-da89-47c4-fac6-0e1c5690f59f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20000 entries, 0 to 19999\n",
            "Data columns (total 2 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   publish_date   20000 non-null  int64 \n",
            " 1   headline_text  20000 non-null  object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 312.6+ KB\n"
          ]
        }
      ],
      "source": [
        "# TODO: Perform a short EDA\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qlb1eKS4ast2"
      },
      "source": [
        "Now perform all the needed preprocessing on those headlines: case lowering, tokenization, punctuation removal, stopwords removal, stemming/lemmatization."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk \n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrHnRTtrgcLx",
        "outputId": "da72c572-eaa9-4bdf-816e-870654ef6d0b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNORAFHgast3",
        "outputId": "98b85afd-e82f-4704-b467-7f08348ff433"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [ute, driver, hurt, intersect, crash]\n",
              "1                       [die, cycl, accid]\n",
              "2          [bumper, oliv, harvest, expect]\n",
              "3    [replica, replac, northernmost, sign]\n",
              "4          [wood, target, perfect, season]\n",
              "Name: stemmed, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# TODO: Preprocess the input data\n",
        "\n",
        "#Tokenizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "df['tokenize'] = df['headline_text'].apply(lambda row: word_tokenize(row))\n",
        "\n",
        "#punctuation removal\n",
        "df['alphanumeric'] = df['tokenize'].apply(lambda row: [\n",
        "     word for word in row if word.isalpha()\n",
        "])\n",
        "\n",
        "#stopword removal\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')\n",
        "df['stop'] = df['alphanumeric'].apply(lambda row: [\n",
        "                                                  word for word in row if word not in stop\n",
        "])\n",
        "\n",
        "#Stemming\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "df['stemmed'] = df['stop'].apply(lambda row: [\n",
        "                        stemmer.stem(word) for word in row                      \n",
        "])\n",
        "\n",
        "df['stemmed'].head()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ShINygiast3"
      },
      "source": [
        "Now use Gensim to compute a BOW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0zif1Ghast3",
        "outputId": "132e3db3-6c3f-4581-d2ab-51422989900d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:1970: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  result = asarray(a).shape\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)], [(5, 1), (6, 1), (7, 1)]]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# TODO: Compute the BOW using Gensim\n",
        "from gensim.corpora import Dictionary\n",
        "\n",
        "dictionary = Dictionary(df['stemmed'])\n",
        "\n",
        "BOW = [dictionary.doc2bow(document) for document in df['stemmed']]\n",
        "print(np.shape(BOW))\n",
        "BOW[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YI7vyVtLast3"
      },
      "source": [
        "Compute the TF-IDF using Gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxpGxOxoast3",
        "outputId": "2db9ba38-229d-4d9e-a1fb-9f6e20389d19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:1970: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  result = asarray(a).shape\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.interfaces.TransformedCorpus at 0x7f57d4edd0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# TODO: Compute TF-IDF\n",
        "from gensim.models import TfidfModel\n",
        "\n",
        "tfidf_model = TfidfModel(BOW)\n",
        "tfidf = tfidf_model[BOW]\n",
        "\n",
        "print(np.shape(tfidf))\n",
        "tfidf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rJVsL9Dast3"
      },
      "source": [
        "Finally compute the **LSA** (also called LSI) using Gensim, for a given number of Topics that you choose yourself"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GgaV8xWqast4"
      },
      "outputs": [],
      "source": [
        "# TODO: Compute LSA\n",
        "from gensim.models import LsiModel\n",
        "\n",
        "lsi_model = LsiModel(BOW, id2word=dictionary, num_topics=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlTXRi6gast4"
      },
      "source": [
        "For each of the topic, show the most significant words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unVDVDJ4ast4",
        "outputId": "4589777c-ede4-4356-d02e-a6ca26f47b84"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, '0.751*\"polic\" + 0.404*\"man\" + 0.207*\"charg\"'),\n",
              " (1, '0.669*\"man\" + -0.575*\"polic\" + 0.330*\"charg\"'),\n",
              " (2, '0.655*\"new\" + 0.298*\"plan\" + 0.242*\"say\"'),\n",
              " (3, '0.703*\"new\" + -0.343*\"say\" + -0.334*\"plan\"')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# TODO: Print the 3 or 4 most significant words of each topic\n",
        "lsi_model.print_topics(num_topics=4, num_words=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWJZw9lLast4"
      },
      "source": [
        "What do you think about those results?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qx55nDbiast4"
      },
      "source": [
        "Now let's try to use LDA instead of LSA using Gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zgXD35Kxast4"
      },
      "outputs": [],
      "source": [
        "# TODO: Compute LDA\n",
        "from gensim.models import LsiModel\n",
        "\n",
        "lda_model = LsiModel(BOW, id2word=dictionary, num_topics=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAgO4LkQast4",
        "outputId": "9292e395-f310-445c-cda4-b14e103f8701"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, '0.752*\"polic\" + 0.404*\"man\" + 0.208*\"charg\" + 0.133*\"new\"'),\n",
              " (1, '0.670*\"man\" + -0.575*\"polic\" + 0.328*\"charg\" + 0.165*\"court\"'),\n",
              " (2, '-0.654*\"new\" + -0.298*\"plan\" + -0.242*\"say\" + 0.241*\"man\"'),\n",
              " (3, '0.705*\"new\" + -0.343*\"say\" + -0.328*\"plan\" + -0.267*\"govt\"')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# TODO: print the most frequent words of each topic\n",
        "lda_model.print_topics(num_topics=4, num_words=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XB-E0oZhast4"
      },
      "source": [
        "Now, how does it work with LDA?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEcLoCeEast4"
      },
      "source": [
        "Let's make some visualization of the LDA results using pyLDAvis."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyLDAvis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0iXo1Rhxdua",
        "outputId": "99a48ca5-8bf7-473e-b239-89d94e90ece1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.7/dist-packages (3.3.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (3.6.0)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.3.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.11.3)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.17)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.4.1)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.8.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.1.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (57.4.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyLDAvis) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->pyLDAvis) (6.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->pyLDAvis) (2.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from numexpr->pyLDAvis) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->numexpr->pyLDAvis) (3.0.9)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyLDAvis) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "JVIyirhBast4",
        "outputId": "bd2044e6-e643-4cc6-f637-c59548e46942"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-9e4b6885c0a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgensim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgensim_models\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgensimvis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyLDAvis.gensim'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# TODO: show visualization results of the LDA\n",
        "import pyLDAvis\n",
        "\n",
        "import pyLDAvis.gensim\n",
        "import pyLDAvis.gensim_models as gensimvis\n",
        "pyLDAvis.enable_notebook\n",
        "vis = pyLDAvis.gensim.prepare(lda_model,BOW, dictionary)\n",
        "vis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ym2qy-YYast5"
      },
      "source": [
        "Depending on your results, you can try to fine tune the algorithm: number of topics, hyperparameters...\n",
        "And check with others their results."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "News-Topic-Modelling(1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}